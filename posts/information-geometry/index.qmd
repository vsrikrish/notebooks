---
title: "Information Geometry"
date: "2023-06-14"
categories: [stats]
date-modified: "2023-06-14"
---

**This is a placeholder as I read more.**

Applications of differential geometry to statistics, using Kullback-Leibler divergence as a pseudo-metric^[K-L divergence isn't symmetric, so it isn't a metric.] and Fisher information as curvature. This lets use some powerful results about manifolds and to think about coordinate-free statistics. I think this could also be useful in analyzing high-dimensional simulation model output, because the outputs aren't actually independent, and looking at the manifold associated with a particular distribution of outputs could result in some dimension reduction without linearization.

I'm interested in:

- Model selection via information geometry (such as methods like the various Watanabe-*x* information criteria).
- Scenario discovery by looking at the "shapes" of ensembles of model runs corresponding to different states of the world (but allowing for stochastic forcings). The rough idea is that this corresponds more directly with the XLRM framing of a decision problem [@Lempert2003-va]: look at the sub-ensembles corresponding to particular levers ("L"), which are the things you can control, and/or some of the uncertainties ("X") that are observable or predictable, and look at how the resulting distributions differ. Then we can identify representative scenarios which have anomalous or interesting distributions.
- Network embeddings: multi-sector systems can be thought of as very complex networks, and being able to embed the network dynamics into some latent space might be useful.

## Relevant Readings

### Overview

- Amari, S.-I., Barndorff-Nielsen, O. E., Kass, R. E., Lauritzen, S. L., & Rao, C. R. (1987). *Differential geometry in statistical inference*. Institute of Mathematical Statistics. Retrieved from <https://projecteuclid.org/ebooks/institute-of-mathematical-statistics-lecture-notes-monograph-series/Differential-geometry-in-statistical-inference/toc/10.1214/lnms/1215467056>
- Toussaint, M. (2004, August 20). Notes on information geometry and evolutionary processes. arXiv [nlin.AO]. Retrieved from <http://arxiv.org/abs/nlin/0408040>
- Ay, N., Jost, J., Lê, H. V., & Schwachhöfer, L. (2012, July 28). Information geometry and sufficient statistics. arXiv [math.ST]. <https://doi.org/10.1007/s00440-014-0574-8>
- Dodson, C. T. J., & Wang, H. (2001). Iterative Approximation of Statistical Distributions and Relation to Information Geometry. *Statistical Inference for Stochastic Processes*, 4(3), 307–318. <https://doi.org/10.1023/a:1012289028897>
- Ollivier, Y., Arnold, L., Auger, A., & Hansen, N. (2017). Information-Geometric Optimization Algorithms: A Unifying Picture via Invariance Principles. *Journal of Machine Learning Research: JMLR*, 18(18), 1–65. <https://doi.org/10.1145/1569901.1569976>
- Amari, S.-I. (2001). Information geometry on hierarchy of probability distributions. *IEEE Transactions on Information Theory*, 47(5), 1701–1711. <https://doi.org/10.1109/18.930911>


### Fisher Information

- Calmet, X., & Calmet, J. (2005). Dynamics of the Fisher information metric. *Physical Review. E, Statistical, Nonlinear, and Soft Matter Physics*, 71(5 Pt 2), 056109. <https://doi.org/10.1103/PhysRevE.71.056109>
- Carter, K. M., Raich, R., Finn, W. G., & Hero, A. O. (2008, February 14). *FINE: Fisher Information Non-parametric Embedding*. arXiv [stat.ML]. Retrieved from <http://arxiv.org/abs/0802.2050>

### Model Selection

- Myung, I. J., Balasubramanian, V., & Pitt, M. A. (2000). Counting probability distributions: differential geometry and model selection. *Proceedings of the National Academy of Sciences of the United States of America*, 97(21), 11170–11175. <https://doi.org/10.1073/pnas.170283897>
- Watanabe, S. (2010). Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular learning theory. *Journal of Machine Learning Research: JMLR*, 11, 3571–3594. Retrieved from <http://arxiv.org/abs/1004.2316>
- Watanabe, S. (2011). *Algebraic Geometry and Statistical Learning Theory*. Cambridge University Press.