<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Notebooks</title>
<link>https://viveks.me/notebooks/index.html</link>
<atom:link href="https://viveks.me/notebooks/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.3.361</generator>
<lastBuildDate>Wed, 14 Jun 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>Information Geometry</title>
  <link>https://viveks.me/notebooks/posts/information-geometry/index.html</link>
  <description><![CDATA[ 



<p><strong>This is a placeholder as I read more.</strong></p>
<div class="page-columns page-full"><p>Applications of differential geometry to statistics, using Kullback-Leibler divergence as a pseudo-metric<sup>1</sup> and Fisher information as curvature. This lets use some powerful results about manifolds and to think about coordinate-free statistics. I think this could also be useful in analyzing high-dimensional simulation model output, because the outputs aren’t actually independent, and looking at the manifold associated with a particular distribution of outputs could result in some dimension reduction without linearization.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;K-L divergence isn’t symmetric, so it isn’t a metric.</p></li></div></div>
<p>I’m interested in:</p>
<ul>
<li>Model selection via information geometry (such as methods like the various Watanabe-<em>x</em> information criteria).</li>
<li>Scenario discovery by looking at the “shapes” of ensembles of model runs corresponding to different states of the world (but allowing for stochastic forcings). The rough idea is that this corresponds more directly with the XLRM framing of a decision problem <span class="citation" data-cites="Lempert2003-va">(Lempert et al., 2003)</span>: look at the sub-ensembles corresponding to particular levers (“L”), which are the things you can control, and/or some of the uncertainties (“X”) that are observable or predictable, and look at how the resulting distributions differ. Then we can identify representative scenarios which have anomalous or interesting distributions.</li>
<li>Network embeddings: multi-sector systems can be thought of as very complex networks, and being able to embed the network dynamics into some latent space might be useful.</li>
</ul>
<div class="no-row-height column-margin column-container"><div id="ref-Lempert2003-va" class="csl-entry">
Lempert, R. J., Popper, S. W., &amp; Bankes, S. C. (2003). <em>Shaping the next one hundred years: New methods for quantitative, long-term policy analysis</em>. Santa Monica, CA: RAND.
</div></div><section id="relevant-readings" class="level2">
<h2 class="anchored" data-anchor-id="relevant-readings">Relevant Readings</h2>
<section id="overview" class="level3">
<h3 class="anchored" data-anchor-id="overview">Overview</h3>
<ul>
<li>Amari, S.-I., Barndorff-Nielsen, O. E., Kass, R. E., Lauritzen, S. L., &amp; Rao, C. R. (1987). <em>Differential geometry in statistical inference</em>. Institute of Mathematical Statistics. Retrieved from <a href="https://projecteuclid.org/ebooks/institute-of-mathematical-statistics-lecture-notes-monograph-series/Differential-geometry-in-statistical-inference/toc/10.1214/lnms/1215467056" class="uri">https://projecteuclid.org/ebooks/institute-of-mathematical-statistics-lecture-notes-monograph-series/Differential-geometry-in-statistical-inference/toc/10.1214/lnms/1215467056</a></li>
<li>Toussaint, M. (2004, August 20). Notes on information geometry and evolutionary processes. arXiv [nlin.AO]. Retrieved from <a href="http://arxiv.org/abs/nlin/0408040" class="uri">http://arxiv.org/abs/nlin/0408040</a></li>
<li>Ay, N., Jost, J., Lê, H. V., &amp; Schwachhöfer, L. (2012, July 28). Information geometry and sufficient statistics. arXiv [math.ST]. <a href="https://doi.org/10.1007/s00440-014-0574-8" class="uri">https://doi.org/10.1007/s00440-014-0574-8</a></li>
<li>Dodson, C. T. J., &amp; Wang, H. (2001). Iterative Approximation of Statistical Distributions and Relation to Information Geometry. <em>Statistical Inference for Stochastic Processes</em>, 4(3), 307–318. <a href="https://doi.org/10.1023/a:1012289028897" class="uri">https://doi.org/10.1023/a:1012289028897</a></li>
<li>Ollivier, Y., Arnold, L., Auger, A., &amp; Hansen, N. (2017). Information-Geometric Optimization Algorithms: A Unifying Picture via Invariance Principles. <em>Journal of Machine Learning Research: JMLR</em>, 18(18), 1–65. <a href="https://doi.org/10.1145/1569901.1569976" class="uri">https://doi.org/10.1145/1569901.1569976</a></li>
<li>Amari, S.-I. (2001). Information geometry on hierarchy of probability distributions. <em>IEEE Transactions on Information Theory</em>, 47(5), 1701–1711. <a href="https://doi.org/10.1109/18.930911" class="uri">https://doi.org/10.1109/18.930911</a></li>
</ul>
</section>
<section id="fisher-information" class="level3">
<h3 class="anchored" data-anchor-id="fisher-information">Fisher Information</h3>
<ul>
<li>Calmet, X., &amp; Calmet, J. (2005). Dynamics of the Fisher information metric. <em>Physical Review. E, Statistical, Nonlinear, and Soft Matter Physics</em>, 71(5 Pt 2), 056109. <a href="https://doi.org/10.1103/PhysRevE.71.056109" class="uri">https://doi.org/10.1103/PhysRevE.71.056109</a></li>
<li>Carter, K. M., Raich, R., Finn, W. G., &amp; Hero, A. O. (2008, February 14). <em>FINE: Fisher Information Non-parametric Embedding</em>. arXiv [stat.ML]. Retrieved from <a href="http://arxiv.org/abs/0802.2050" class="uri">http://arxiv.org/abs/0802.2050</a></li>
</ul>
</section>
<section id="model-selection" class="level3">
<h3 class="anchored" data-anchor-id="model-selection">Model Selection</h3>
<ul>
<li>Myung, I. J., Balasubramanian, V., &amp; Pitt, M. A. (2000). Counting probability distributions: differential geometry and model selection. <em>Proceedings of the National Academy of Sciences of the United States of America</em>, 97(21), 11170–11175. <a href="https://doi.org/10.1073/pnas.170283897" class="uri">https://doi.org/10.1073/pnas.170283897</a></li>
<li>Watanabe, S. (2010). Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular learning theory. <em>Journal of Machine Learning Research: JMLR</em>, 11, 3571–3594. Retrieved from <a href="http://arxiv.org/abs/1004.2316" class="uri">http://arxiv.org/abs/1004.2316</a></li>
<li>Watanabe, S. (2011). <em>Algebraic Geometry and Statistical Learning Theory</em>. Cambridge University Press.</li>
</ul>



</section>
</section>


 ]]></description>
  <category>stats</category>
  <guid>https://viveks.me/notebooks/posts/information-geometry/index.html</guid>
  <pubDate>Wed, 14 Jun 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Agent-Based Models</title>
  <link>https://viveks.me/notebooks/posts/agent-based-modeling/index.html</link>
  <description><![CDATA[ 



<div class="page-columns page-full"><p>Agent-based models are useful for simulating heterogeneous agents which interact with each other, particularly under nonequilibrium conditions<sup>1</sup>.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;This notebook will not focus on particular applications — there are a lot of them, but I’m more interested in the underlying methods and what they mean for interpretation of ABM results.</p></li></div></div>
<p>But..</p>
<ul>
<li>They are notoriously difficult to calibrate statistically<sup>2</sup>, and so, particularly in environmental applications, are often not calibrated or the calibration is done so poorly that it may as well not have been done at all (a topic that I am very interested in, so that gets <a href="../abm-calibration/">its own notebook</a>). This also means they are rarely validated in a way which doesn’t trivially follow from the “calibration,” and yet they are used to breathlessly make projections. Weird.</li>
<li>They are easy to overstuff with whatever state information variables one wants (this ties to calibration, of course).</li>
<li>To me, this raises of the question of how often ABMs are designed to be “compatible” with some data, rather than starting from theory and finding appropriate data. This is fundamentally backwards.</li>
<li>Sometimes people use ML approaches instead of parametric utility functions. That’s fine for prediction, I suppose, but overfitting worries me, and it’s hard then to compare models, and structural uncertainty is a beast <span class="citation" data-cites="Yoon2023-sp">(Yoon et al., 2023)</span>.</li>
</ul>
<div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;Which is important given <a href="../model-discrepancy/">model discrepancy</a> and the features that make ABMs interesting, like path dependence…</p></li><div id="ref-Yoon2023-sp" class="csl-entry">
Yoon, J., Wan, H., Daniel, B., Srikrishnan, V., &amp; Judi, D. (2023). <span class="nocase">Structural model choices regularly overshadow parametric uncertainty in agent-based simulations of household flood risk outcomes</span>. <em>Comput. Environ. Urban Syst.</em>, <em>103</em>, 101979. <a href="https://doi.org/10.1016/j.compenvurbsys.2023.101979">https://doi.org/10.1016/j.compenvurbsys.2023.101979</a>
</div><div id="ref-Bankes1993-lj" class="csl-entry">
Bankes, S. (1993). <span class="nocase">Exploratory modeling for policy analysis</span>. <em>Oper. Res.</em>, <em>41</em>, 435–449. <a href="https://doi.org/10.1287/opre.41.3.435">https://doi.org/10.1287/opre.41.3.435</a>
</div></div><div class="page-columns page-full"><p>For the purposes of generative social science, I think these are more useful for exploratory analyses than consolidative modeling <span class="citation" data-cites="Bankes1993-lj">(Bankes, 1993)</span>, but that requires careful accounting of both parametric and structural uncertainty<sup>3</sup>. That being said, I am interested in quite a few questions related to ABMs — not just calibration and inference, but broader questions about structural uncertainty, diagnosing and understanding the implications of equi- and multifinality<sup>4</sup>, and uncertainty propagation.</p><div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;Particularly as both equifinality and multifinality come up frequently.</p></li><li id="fn4"><p><sup>4</sup>&nbsp;I don’t like these terms, but they are succint.</p></li></div></div>
<section id="relevant-reading" class="level2">
<h2 class="anchored" data-anchor-id="relevant-reading">Relevant Reading</h2>
<section id="overviews" class="level3">
<h3 class="anchored" data-anchor-id="overviews">Overviews</h3>
<ul>
<li>Epstein, J. M. (1999). Agent-based computational models and generative social science. <em>Complexity</em>, 4(5), 41–60. <a href="https://doi.org/10.1002/(SICI)1099-0526(199905/06)4:5%3C41::AID-CPLX9" class="uri">https://doi.org/10.1002/(SICI)1099-0526(199905/06)4:5&lt;41::AID-CPLX9</a>3.0.CO;2-F&gt;</li>
<li>Macy, M. W., &amp; Willer, R. (2002). From factors to actors: Computational sociology and agent-based modeling. <em>Annual Review of Sociology</em>, 28(1), 143–166. <a href="https://doi.org/10.1146/annurev.soc.28.110601.141117" class="uri">https://doi.org/10.1146/annurev.soc.28.110601.141117</a></li>
<li>Shalizi, C. R. (2003, July 9). Methods and techniques of complex systems science: An overview. arXiv [nlin.AO]. Retrieved from <a href="http://arxiv.org/abs/nlin/0307015" class="uri">http://arxiv.org/abs/nlin/0307015</a></li>
<li>Farmer, J. D., &amp; Foley, D. (2009). The economy needs agent-based modelling. <em>Nature</em>, 460(7256), 685–686. <a href="https://doi.org/10.1038/460685a" class="uri">https://doi.org/10.1038/460685a</a></li>
<li>Lempert, R. (2002). Agent-based modeling as organizational and public policy simulators. <em>Proceedings of the National Academy of Sciences of the United States of America</em>, 99 Suppl 3(Supplement 3), 7195–7196. <a href="https://doi.org/10.1073/pnas.072079399" class="uri">https://doi.org/10.1073/pnas.072079399</a></li>
<li>Macal, C. M. (2016). Everything you need to know about agent-based modelling and simulation. <em>Journal of Simulation</em>, 10(2), 144–156. <a href="https://doi.org/10.1057/jos.2016.7" class="uri">https://doi.org/10.1057/jos.2016.7</a></li>
<li>Heard, D., Dent, G., Schifeling, T., &amp; Banks, D. (2015). Agent-Based Models and Microsimulation. <em>Annual Review of Statistics and Its Application</em>, 2(1), 259–272. <a href="https://doi.org/10.1146/annurev-statistics-010814-020218" class="uri">https://doi.org/10.1146/annurev-statistics-010814-020218</a></li>
<li>Janssen, M. A., &amp; Ostrom, E. (2006). Empirically based, agent-based models. <em>Ecology and Society</em>, 11(2), art37. <a href="https://doi.org/10.5751/ES-01861-110237" class="uri">https://doi.org/10.5751/ES-01861-110237</a></li>
<li>Adami, C., Schossau, J., &amp; Hintze, A. (2014, April 3). Evolutionary game theory using agent-based methods. arXiv [q-bio.PE]. Retrieved from <a href="http://arxiv.org/abs/1404.0994" class="uri">http://arxiv.org/abs/1404.0994</a></li>
</ul>
</section>
<section id="philosophical-foundations" class="level3">
<h3 class="anchored" data-anchor-id="philosophical-foundations">Philosophical Foundations</h3>
<ul>
<li>Leombruni, R., &amp; Richiardi, M. (2005). Why are economists sceptical about agent-based simulations? <em>Physica A</em>, 355(1), 103–109. <a href="https://doi.org/10.1016/j.physa.2005.02.072" class="uri">https://doi.org/10.1016/j.physa.2005.02.072</a></li>
<li>Lehtinen, A., &amp; Kuorikoski, J. (2007). Computing the perfect model: Why do economists shun simulation? <em>Philosophy of Science</em>, 74(3), 304–329. <a href="https://doi.org/10.1086/522359" class="uri">https://doi.org/10.1086/522359</a></li>
<li>Grüne-Yanoff, T. (2009). The explanatory potential of artificial societies. <em>Synthese</em>, 169(3), 539–555. <a href="https://doi.org/10.1007/s11229-008-9429-0" class="uri">https://doi.org/10.1007/s11229-008-9429-0</a></li>
<li>Marchionni, C., &amp; Ylikoski, P. (2013). <em>Generative explanation and individualism in agent-based simulation</em>. Philosophy of the Social Sciences, 43(3), 323–340. <a href="https://doi.org/10.1177/0048393113488873" class="uri">https://doi.org/10.1177/0048393113488873</a></li>
<li>Ylikoski, P. (2014). Agent-based simulation and sociological understanding. <em>Perspectives on Science: Historical, Philosophical, Social</em>, 22(3), 318–335. <a href="https://doi.org/10.1162/posc_a_00136" class="uri">https://doi.org/10.1162/posc_a_00136</a></li>
</ul>
</section>
<section id="challenges" class="level3">
<h3 class="anchored" data-anchor-id="challenges">Challenges</h3>
<ul>
<li>Crooks, A., Castle, C., &amp; Batty, M. (2008). Key challenges in agent-based modelling for geo-spatial simulation. <em>Computers, Environment and Urban Systems</em>, 32(6), 417–430. <a href="https://doi.org/10.1016/j.compenvurbsys.2008.09.004" class="uri">https://doi.org/10.1016/j.compenvurbsys.2008.09.004</a></li>
<li>Filatova, T., Verburg, P. H., Parker, D. C., &amp; Stannard, C. A. (2013). Spatial agent-based models for socio-ecological systems: challenges and prospects. <em>Environmental Modelling &amp; Software</em>, 45, 1–7. <a href="https://doi.org/10.1016/j.envsoft.2013.03.017" class="uri">https://doi.org/10.1016/j.envsoft.2013.03.017</a></li>
<li>Lee, J.-S., Filatova, T., Ligmann-Zielinska, A., Hassani-Mahmooei, B., Stonedahl, F., Lorscheid, I., et al.&nbsp;(2015). The complexities of agent-based modeling output analysis. <em>Journal of Artificial Societies and Social Simulation: JASSS</em>, 18(4), 4. <a href="https://doi.org/10.18564/jasss.2897" class="uri">https://doi.org/10.18564/jasss.2897</a></li>
<li>Kieu, L.-M., Malleson, N., &amp; Heppenstall, A. (2020). Dealing with uncertainty in agent-based models for short-term predictions. <em>Royal Society Open Science</em>, 7(1), 191074. <a href="https://doi.org/10.1098/rsos.191074" class="uri">https://doi.org/10.1098/rsos.191074</a></li>
<li>Boero, R., &amp; Squazzoni, Flaminio. (2005). Does Empirical Embeddedness Matter? Methodological Issues on Agent-Based Models for Analytical Social Science. <em>Journal of Artificial Societies and Social Simulation</em>, 8(4), 6. Retrieved from <a href="http://jasss.soc.surrey.ac.uk/8/4/6.html" class="uri">http://jasss.soc.surrey.ac.uk/8/4/6.html</a></li>
<li>O’Sullivan, D., Evans, T., Manson, S., Metcalf, S., Ligmann-Zielinska, A., &amp; Bone, C. (2016). Strategic directions for agent-based modeling: avoiding the YAAWN syndrome. <em>Journal of Land Use Science</em>, 11(2), 177–187. <a href="https://doi.org/10.1080/1747423X.2015.1030463" class="uri">https://doi.org/10.1080/1747423X.2015.1030463</a></li>
<li>Yoon, J., Wan, H., Daniel, B., Srikrishnan, V., &amp; Judi, D. (2023). Structural model choices regularly overshadow parametric uncertainty in agent-based simulations of household flood risk outcomes. <em>Computers, Environment and Urban Systems</em>, 103, 101979. <a href="https://doi.org/10.1016/j.compenvurbsys.2023.101979" class="uri">https://doi.org/10.1016/j.compenvurbsys.2023.101979</a></li>
</ul>
</section>
<section id="methods" class="level3">
<h3 class="anchored" data-anchor-id="methods">Methods</h3>
<ul>
<li>Banisch, S., Lima, R., &amp; Araújo, T. (2011, August 8). <em>Agent based models and opinion dynamics as Markov chains</em>. arXiv [nlin.AO]. Retrieved from <a href="http://arxiv.org/abs/1108.1716" class="uri">http://arxiv.org/abs/1108.1716</a></li>
<li>Valogianni, K., &amp; Padmanabhan, B. (2022). Causal ABMs: Learning Plausible Causal Models using Agent-based Modeling. In The <em>KDD’22 Workshop on Causal Discovery</em> (pp.&nbsp;3–29). PMLR. Retrieved from <a href="https://proceedings.mlr.press/v185/valogianni22a.html" class="uri">https://proceedings.mlr.press/v185/valogianni22a.html</a></li>
<li>Grimm, V. (2005). Pattern-oriented modeling of agent-based complex systems: lessons from ecology. Science, 310(5750), 987–991. https://doi.org/10.1126/science.1116681</li>
<li>Wilensky, U., &amp; Rand, W. (2007). Making models match: Replicating an agent-based model. <em>Journal of Artificial Societies and Social Simulation</em>, 10(4), 2. Retrieved from <a href="http://jasss.soc.surrey.ac.uk/10/4/2.html" class="uri">http://jasss.soc.surrey.ac.uk/10/4/2.html</a></li>
<li>Anzola, D. (2021). The Theory-Practice Gap in the Evaluation of Agent-Based Social Simulations. <em>Science in Context</em>, 34(3), 393–410. <a href="https://doi.org/10.1017/S0269889722000242" class="uri">https://doi.org/10.1017/S0269889722000242</a></li>
<li>Băbeanu, A.-I., Filatova, T., Kwakkel, J. H., &amp; Yorke-Smith, N. (2023, April 4). Adaptive parallelization of multi-agent simulations with localized dynamics. arXiv [cs.DC]. Retrieved from <a href="http://arxiv.org/abs/2304.01724" class="uri">http://arxiv.org/abs/2304.01724</a></li>
<li>Bao, L., &amp; Fritchman, J. C. (2018). Information of complex systems and applications in agent based modeling. <em>Scientific Reports</em>, 8(1), 6177. <a href="https://doi.org/10.1038/s41598-018-24570-1" class="uri">https://doi.org/10.1038/s41598-018-24570-1</a></li>
<li>Borgonovo, E., Pangallo, M., Rivkin, J., Rizzo, L., &amp; Siggelkow, N. (2022). Sensitivity analysis of agent-based models: a new protocol. <em>Computational &amp; Mathematical Organization Theory</em>, 28(1), 52–94. <a href="https://doi.org/10.1007/s10588-021-09358-5" class="uri">https://doi.org/10.1007/s10588-021-09358-5</a></li>
<li>Will, M., Groeneveld, J., Frank, K., &amp; Müller, B. (2020). Combining social network analysis and agent-based modelling to explore dynamics of human interaction: A review. <em>Socio-Environmental Systems Modelling</em>, 2, 16325. <a href="https://doi.org/10.18174/sesmo.2020a16325" class="uri">https://doi.org/10.18174/sesmo.2020a16325</a></li>
<li>Brown, D. G., Page, S., Riolo, R., Zellner, M., &amp; Rand, W. (2005). Path dependence and the validation of agent‐based spatial models of land use. <em>International Journal of Geographical Information Science: IJGIS</em>, 19(2), 153–174. <a href="https://doi.org/10.1080/13658810410001713399" class="uri">https://doi.org/10.1080/13658810410001713399</a></li>
<li>Groeneveld, J., Müller, B., Buchmann, C. M., Dressler, G., Guo, C., Hase, N., et al.&nbsp;(2017). Theoretical foundations of human decision-making in agent-based land use models – A review. <em>Environmental Modelling &amp; Software</em>, 87, 39–48. <a href="https://doi.org/10.1016/j.envsoft.2016.10.008" class="uri">https://doi.org/10.1016/j.envsoft.2016.10.008</a></li>
<li>Thiem, T. N., Kemeth, F. P., Bertalan, T., Laing, C. R., &amp; Kevrekidis, I. G. (2021). Global and local reduced models for interacting, heterogeneous agents. <em>Chaos</em>, 31, 073139. <a href="https://doi.org/10.1063/5.0055840" class="uri">https://doi.org/10.1063/5.0055840</a></li>
</ul>



</section>
</section>


 ]]></description>
  <category>modeling</category>
  <guid>https://viveks.me/notebooks/posts/agent-based-modeling/index.html</guid>
  <pubDate>Tue, 13 Jun 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Model Discrepancy</title>
  <link>https://viveks.me/notebooks/posts/model-discrepancy/index.html</link>
  <description><![CDATA[ 



<p>Model discrepancy refers to systematic mismatches between model and data. This is conceptually different from observation error (which is typically assumed to be white noise), though both combine to produce the model residuals. When discrepancy is assumed to be normal, non-identifiability makes it challenging to separate from observation error, so these are usually lumped together, but this is usually a poor choice in environmental application.</p>
<section id="relevant-reading" class="level2">
<h2 class="anchored" data-anchor-id="relevant-reading">Relevant Reading</h2>
<ul>
<li>Kennedy, M. C., &amp; O’Hagan, A. (2001). Bayesian calibration of computer models. <em>Journal of the Royal Statistical Society. Series B, Statistical Methodology</em>, 63(3), 425–464. <a href="https://doi.org/10.1111/1467-9868.00294" class="uri">https://doi.org/10.1111/1467-9868.00294</a></li>
<li>Brynjarsdóttir, J., &amp; OʼHagan, A. (2014). Learning about physical parameters: the importance of model discrepancy. <em>Inverse Problems</em>, 30(11), 114007. <a href="https://doi.org/10.1088/0266-5611/30/11/114007" class="uri">https://doi.org/10.1088/0266-5611/30/11/114007</a></li>
<li>Jiang, B., Wu, T.-Y., &amp; Wong, W. H. (2018). Approximate Bayesian Computation with Kullback-Leibler Divergence as Data Discrepancy. In A. Storkey &amp; F. Perez-Cruz (Eds.), <em>Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics</em> (Vol. 84, pp.&nbsp;1711–1721). Lanzarote, Spain: PMLR. Retrieved from <a href="https://proceedings.mlr.press/v84/jiang18a.html" class="uri">https://proceedings.mlr.press/v84/jiang18a.html</a></li>
<li>Gardner, P., Rogers, T. J., Lord, C., &amp; Barthorpe, R. J. (2019). Learning of model discrepancy for structural dynamics applications using Bayesian history matching. <em>Journal of Physics. Conference Series</em>, 1264(1), 012052. <a href="https://doi.org/10.1088/1742-6596/1264/1/012052" class="uri">https://doi.org/10.1088/1742-6596/1264/1/012052</a></li>
</ul>


</section>

 ]]></description>
  <category>stats</category>
  <guid>https://viveks.me/notebooks/posts/model-discrepancy/index.html</guid>
  <pubDate>Sun, 11 Jun 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Robustness</title>
  <link>https://viveks.me/notebooks/posts/robustness/index.html</link>
  <description><![CDATA[ 



<p>Robustness is a vaguely defined term. There are really two different, though related, types of robustness, as the term is commonly used:</p>
<ol type="1">
<li>Robustness of a decision, <em>i.e.</em> how well does a particular decision perform under alternative states of the world (SOWs)?</li>
<li>Robustness of model insights to researcher degrees of freedom/forking paths.</li>
</ol>
<p>The former is the focus in this notebook, though the latter is often more interesting and difficult to quantify; often one has to link back to the original system and ensure that the model was adequate (not <em>valid</em>, as commonly used) and that the insights make sense <span class="citation" data-cites="Oreskes1994-br">(Oreskes et al., 1994)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Oreskes1994-br" class="csl-entry">
Oreskes, N., Shrader-Frechette, K., &amp; Belitz, K. (1994). <span class="nocase">Verification, validation, and confirmation of numerical models in the earth sciences</span>. <em>Science</em>, <em>263</em>, 641–646. <a href="https://doi.org/10.1126/science.263.5147.641">https://doi.org/10.1126/science.263.5147.641</a>
</div></div><div class="page-columns page-full"><p>Assessing the robustness of a decision is best done as a summary of a type of sensitivity: pick a solution that seems acceptable under some decision-making method, and then stress-test it to make sure it performs adequately across scenarios<sup>1</sup>.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;Picking the threshold for adequate peformance is another issue…</p></li></div></div>
<section id="satisfycing" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="satisfycing">Satisfycing</h2>
<p>Satisfycing measures how often a particular performance threshold is reached across the range of states of the world. In other words, assign a 0-1 loss over the tolerable domain <img src="https://latex.codecogs.com/png.latex?D%20%5Csubset%20X">:</p>
<p><img src="https://latex.codecogs.com/png.latex?L(%5Cmathbf%7Bx%7D)%20=%20%5Cbegin%7Bcases%7D0%20&amp;%20%5Cmathbf%7Bx%7D%20%5Cin%20D%20%5C%5C%201%20&amp;%20%5Cmathbf%7Bx%7D%20%5Cnotin%20D.%5Cend%7Bcases%7D"></p>
<p>Then the satisfycing score is</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cint_X%20L(%5Cmathbf%7Bx%7D)%20p(x)%20dx%20=%20%5Cint_D%20p(x)%20dx."></p>
<section id="sensitivity-of-satisfycing-score-to-probabilities" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sensitivity-of-satisfycing-score-to-probabilities">Sensitivity of Satisfycing Score to Probabilities</h3>
<div class="page-columns page-full"><p>This makes the score sensitive to the probability distribution <img src="https://latex.codecogs.com/png.latex?p"> and the tolerable domain <img src="https://latex.codecogs.com/png.latex?D">. As a result, even if the tolerable threshold is well-defined<sup>2</sup> this begs the question somewhat, as the robustness scores will depend on how frequently poorly-performing scenarios are sampled. A uniform distribution may be the worst option of all<sup>3</sup>. A good sensitivity analysis can diagnose this type of issue, but may not be reflected in a satisfycing approach. <span class="citation" data-cites="Quinn2020-cr">Quinn et al. (2020)</span> shows that this notion of robustness is not itself robust to different scenario samples; this is related to fundamental issues with “Robust Bayes” <span class="citation" data-cites="Gelman2006-eh">(Gelman, 2006)</span>.</p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;Which seems unlikely across stakeholders, but let’s grant that for now…</p></li><li id="fn3"><p><sup>3</sup>&nbsp;The principle of insufficient reason is only one way to express ignorance, and makes no sense for subjective probabilities <span class="citation" data-cites="Kass1996-ro">(Kass &amp; Wasserman, 1996)</span>.</p><div id="ref-Kass1996-ro" class="csl-entry">
Kass, R. E., &amp; Wasserman, L. (1996). <span class="nocase">The selection of prior distributions by formal rules</span>. <em>J. Am. Stat. Assoc.</em>, <em>91</em>, 1343–1370. <a href="https://doi.org/10.1080/01621459.1996.10477003">https://doi.org/10.1080/01621459.1996.10477003</a>
</div></li><div id="ref-Quinn2020-cr" class="csl-entry">
Quinn, J. D., Hadjimichael, A., Reed, P. M., &amp; Steinschneider, S. (2020). <span class="nocase">Can exploratory modeling of water scarcity vulnerabilities and robustness be scenario neutral?</span> <em>Earth’s Future</em>, <em>8</em>, e2020EF001650. <a href="https://doi.org/10.1029/2020EF001650">https://doi.org/10.1029/2020EF001650</a>
</div><div id="ref-Gelman2006-eh" class="csl-entry">
Gelman, A. (2006). <span class="nocase">The boxer, the wrestler, and the coin flip: A paradox of robust bayesian inference and belief functions</span>. <em>Am. Stat.</em>, <em>60</em>, 146–150. <a href="https://doi.org/10.1198/000313006X106190">https://doi.org/10.1198/000313006X106190</a>
</div></div></div>
<p>For analyzing a single decision or a set of decisions, this approach is likely fine to understand the sensitivity of the decision’s adequacy to mis-parameterization. Things get worse when trying to use robustness as an objective for the decision analysis, particularly when probabilities are diffuse or ill-characterized, as obtaining the state(s) of the world used in the analysis is itself fraught and/or relies on subjective probabilities anyway: the resulting decision is itself likely highly sensitive to any number of decisions in the problem setup, and now we’re back at the other kind of robustness.</p>
</section>
<section id="model-discrepancy" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="model-discrepancy">Model Discrepancy</h3>
<div class="page-columns page-full"><p>There’s also another, maybe more fundamental issue: <a href="../model-discrepancy/">model discrepancy</a>. If your performance threshold is <img src="https://latex.codecogs.com/png.latex?%5Ctau"> and the model prediction for a state of the world <img src="https://latex.codecogs.com/png.latex?s"> is <img src="https://latex.codecogs.com/png.latex?F(s)">, you want to know if <img src="https://latex.codecogs.com/png.latex?f(s)%20%3E%20%5Ctau">. But if <img src="https://latex.codecogs.com/png.latex?F"> has a discrepancy <img src="https://latex.codecogs.com/png.latex?%5Czeta(s)">, you could mis-score <img src="https://latex.codecogs.com/png.latex?s"> if <img src="https://latex.codecogs.com/png.latex?%5Czeta"> moves you to the other side of <img src="https://latex.codecogs.com/png.latex?%5Ctau">, with potentially important implications<sup>4</sup></p><div class="no-row-height column-margin column-container"><li id="fn4"><p><sup>4</sup>&nbsp;This isn’t unique to the robustness setting, either: it applies to any model-based decision analysis with a 0-1 loss. For example, we should talk about this more in the context of pathways to zero emissions.</p></li></div></div>
</section>
</section>
<section id="regret" class="level2">
<h2 class="anchored" data-anchor-id="regret">Regret</h2>
<p>Regret is fine and reasonably sensible: it’s a Bayesian score with a loss of the following type:</p>
<p><img src="https://latex.codecogs.com/png.latex?L(%5Cmathbf%7Bx%7D)%20=%20%5Cbegin%7Bcases%7D0%20&amp;%20if%20%5Cmathbf%7Bx%7D%20%5Cin%20D%20%5C%5C%20R(%5C%7C%20%5Cmathbf%7Bx%7D%20-%20%5Ctau%20%5C%7C)%20&amp;%20if%20%5Cmathbf%7Bx%7D%20%5Cnotin%20D,%5Cend%7Bcases%7D"> where <img src="https://latex.codecogs.com/png.latex?%5C%7C%20%5Ccdot%20%5C%7C"> is some metric over outcomes. Nothing too interesting, and likely leads to more sensible rankings than satisfycing when they differ. I also think it’s preferable for decision-making to losses which are more mathematical constructs than decision-relevant, like mean or logarithmic losses. For certain choices of <img src="https://latex.codecogs.com/png.latex?L">, this also helps smooth out the model discrepancy issue, since you can make the loss within some neighborhood of the boundary of <img src="https://latex.codecogs.com/png.latex?D"> positive as a buffer and adjust <img src="https://latex.codecogs.com/png.latex?R"> to smooth the transition from <img src="https://latex.codecogs.com/png.latex?D"> to a high-regret region. It might be interesting to explore this in a quick paper, maybe for the shallow lake problem or coastal flood risk.</p>
</section>
<section id="see-also" class="level2">
<h2 class="anchored" data-anchor-id="see-also">See Also</h2>
<p><a href="../deep-uncertainty-subjective-probability/">Deep Uncertainty and Subjective Probabilities</a></p>
</section>
<section id="relevant-reading" class="level2">
<h2 class="anchored" data-anchor-id="relevant-reading">Relevant Reading</h2>
<ul>
<li>Herman, J. D., Reed, P. M., Zeff, H. B., &amp; Characklis, G. W. (2015). How should robustness be defined for water systems planning under change? <em>Journal of Water Resources Planning and Management</em>, 141(10), 04015012. <a href="https://doi.org/10.1061/(ASCE)WR.1943-5452.0000509" class="uri">https://doi.org/10.1061/(ASCE)WR.1943-5452.0000509</a></li>
<li>Giuliani, M., &amp; Castelletti, A. (4/2016). Is robustness really robust? How different definitions of robustness impact decision-making under climate change. <em>Climatic Change</em>, 135(3–4), 409–424. <a href="https://doi.org/10.1007/s10584-015-1586-9" class="uri">https://doi.org/10.1007/s10584-015-1586-9</a></li>
<li>McPhail, C., Maier, H. R., Kwakkel, J., Giuliani, M., &amp; Westra, S. (2018). Robustness Metrics: How Are They Calculated, When Should They Be Used and Why Do They Give Different Results? <em>Earth’s Future</em>, 6(2)). <a href="https://doi.org/10.1002/2017EF000649" class="uri">https://doi.org/10.1002/2017EF000649</a></li>
<li>McPhail, C., Maier, H. R., Westra, S., Kwakkel, J. H., &amp; Linden, L. (09/2020). Impact of scenario selection on robustness. <em>Water Resources Research</em>, 56(9). <a href="https://doi.org/10.1029/2019WR026515" class="uri">https://doi.org/10.1029/2019WR026515</a></li>
<li>Quinn, J. D., Hadjimichael, A., Reed, P. M., &amp; Steinschneider, S. (2020). Can exploratory modeling of water scarcity vulnerabilities and robustness be scenario neutral? <em>Earth’s Future</em>, 8(11), e2020EF001650. <a href="https://doi.org/10.1029/2020EF001650" class="uri">https://doi.org/10.1029/2020EF001650</a></li>
</ul>



</section>


 ]]></description>
  <category>uncertainty</category>
  <category>decision-making</category>
  <guid>https://viveks.me/notebooks/posts/robustness/index.html</guid>
  <pubDate>Sat, 10 Jun 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>State-Space Reconstruction</title>
  <link>https://viveks.me/notebooks/posts/state-space-reconstruction/index.html</link>
  <description><![CDATA[ 



<p>Given a time series that we assume came from a dynamical system, can we reconstruct the state space of the system from the observations? This is complicated by a few features of chaotic or noisy systems.</p>
<section id="setup-and-theorem" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="setup-and-theorem">Setup and Theorem</h2>
<div class="page-columns page-full"><p>Suppose we have a <em>deterministic</em> dynamical system with state <img src="https://latex.codecogs.com/png.latex?z(t)"> on a smooth manifold of dimension <img src="https://latex.codecogs.com/png.latex?m">. Our observations are <img src="https://latex.codecogs.com/png.latex?x(t)%20=%20g(z(t))"><sup>1</sup>.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;often <img src="https://latex.codecogs.com/png.latex?g(y)%20=%20y%20+%20%5Cvarepsilon_t">, where <img src="https://latex.codecogs.com/png.latex?%5Cvarepsilon_t"> is some noise process, but this can be more complex.</p></li></div></div>
<p>For a time horizon <img src="https://latex.codecogs.com/png.latex?%5Ctau%20%3C%20%5Cinfty"> and a positive integer <img src="https://latex.codecogs.com/png.latex?k">, set <img src="https://latex.codecogs.com/png.latex?s(t)%20=%20(x(t),%20x(t%20-%20%5Ctau),%20x(t%20-%202%5Ctau),%20%5Cldots,%20x(t%20-%20(k-1)%20%5Ctau))."> It turns out <span class="citation" data-cites="Takens1981-gq">(Takens., 1981)</span> that if <img src="https://latex.codecogs.com/png.latex?k%20%5Cgeq%202m+1">, then <img src="https://latex.codecogs.com/png.latex?z(t)%20=%20%5Cphi(s(t))"> for some diffeomorphism <img src="https://latex.codecogs.com/png.latex?%5Cphi">.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Takens1981-gq" class="csl-entry">
Takens., F. (1981). <span class="nocase">Detecting strange attractors in turbulence</span>. In D. A. Rand &amp; L. S. Young (Eds.), <em><span class="nocase"><em>Symposium on Dynamical Systems and Turbulence (</em>Springer Lecture Notes in Mathematics vol. 898)</span></em> (pp. 366–381). Berlin, Germany: Springer. Retrieved from <a href="https://www.crcv.ucf.edu/gauss/info/Takens.pdf">https://www.crcv.ucf.edu/gauss/info/Takens.pdf</a>
</div></div><div class="page-columns page-full"><p>A nice application of this is in the context of climate change. A common tendency along among certain climate-change skeptics<sup>2</sup> was to use Granger causality to claim that warming causes CO<sub>2</sub> increases. This use violates the relevant assumptions of Granger causality, namely that there is no confounding causal influence on both time series<sup>3</sup>. Instead, <span class="citation" data-cites="Van_Nes2015-ua">Nes et al. (2015)</span> show using Takens’ theorem that we get the expected feedbacks on the right time scales.</p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;Who know only enough to make these mistakes but not recognize them!</p></li><li id="fn3"><p><sup>3</sup>&nbsp;In this case, Milankovitch cycles but we also know that the relationship between temperature and CO<sub>2</sub> changes depending on the time scale of interest</p></li><div id="ref-Van_Nes2015-ua" class="csl-entry">
Nes, E. H. van, Scheffer, M., Brovkin, V., Lenton, T. M., Ye, H., Deyle, E., &amp; Sugihara, G. (2015). Causal feedbacks in climate change. <em>Nat. Clim. Chang.</em>, <em>5</em>(5), 445–448. <a href="https://doi.org/10.1038/nclimate2568">https://doi.org/10.1038/nclimate2568</a>
</div></div></div>
</section>
<section id="main-interest" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="main-interest">Main Interest</h2>
<div class="page-columns page-full"><p>My main interest is in getting this to work on multi-sector networks: can we reconstruct the state trajectory of a system of many state variables given a simulation? Using an ensemble of simulations would allow us to look for tipping points or teleconnections or track the propagation of shocks<sup>4</sup>. The complications in making this tractable are stochasticity<sup>5</sup> and dimensionality<sup>6</sup>, but maybe looking at network properties can reduce the dimensionality. Maybe this can be done with the PC algorithm.</p><div class="no-row-height column-margin column-container"><li id="fn4"><p><sup>4</sup>&nbsp;“George Box has [almost] said”The only way to find out what will happen when a complex system is disturbed is to disturb the system, not merely to observe it passively.” These words of caution about “natural experiments” are uncomfortably strong. Yet in today’s world we see no alternative to accepting them as, if anything, too weak.” - Mosteller &amp; Tukey (1977)</p></li><li id="fn5"><p><sup>5</sup>&nbsp;We would need to reconstruct a Markov process</p></li><li id="fn6"><p><sup>6</sup>&nbsp;Finding the relevant DAG is expensive.</p></li></div></div>
</section>
<section id="things-i-need-to-think-about-more" class="level2">
<h2 class="anchored" data-anchor-id="things-i-need-to-think-about-more">Things I Need To Think About More</h2>
<ul>
<li>Methods for reconstructing networks from potentially noisy simulations</li>
<li>Use of network invariants for dimension-reduction. Maybe topological data analysis has some application?</li>
</ul>
</section>
<section id="relevant-reading" class="level2">
<h2 class="anchored" data-anchor-id="relevant-reading">Relevant Reading</h2>
<section id="reconstruction" class="level3">
<h3 class="anchored" data-anchor-id="reconstruction">Reconstruction</h3>
<ul>
<li>Takens., F. (1981). Detecting strange attractors in turbulence. In D. A. Rand &amp; L. S. Young (Eds.), <em>Symposium on Dynamical Systems and Turbulence</em> (Springer Lecture Notes in Mathematics vol.&nbsp;898) (pp.&nbsp;366–381). Berlin, Germany: Springer.</li>
<li>Stark, J., Broomhead, D. S., Davies, M. E., &amp; Huke, J. (1997). Takens embedding theorems for forced and stochastic systems. <em>Nonlinear Analysis, Theory, Methods &amp; Applications</em>, 30(8), 5303–5314. <a href="https://doi.org/10.1016/S0362-546X(96)00149-6" class="uri">https://doi.org/10.1016/S0362-546X(96)00149-6</a></li>
<li>Robinson, J. C. (2005). A topological delay embedding theorem for infinite-dimensional dynamical systems. <em>Nonlinearity</em>, 18(5), 2135. <a href="https://doi.org/10.1088/0951-7715/18/5/013" class="uri">https://doi.org/10.1088/0951-7715/18/5/013</a></li>
<li>Garcia, S. P., &amp; Almeida, J. S. (2006, September 12). Multivariate phase space reconstruction by nearest neighbor embedding with different time delays. arXiv [nlin.CD]. Retrieved from <a href="http://arxiv.org/abs/nlin/0609029" class="uri">http://arxiv.org/abs/nlin/0609029</a></li>
<li>Spirtes, P., Glymour, C., &amp; Scheines, R. (1993). Causation, Prediction, and Search. New York, NY: Springer. <a href="https://doi.org/10.1007/978-1-4612-2748-9" class="uri">https://doi.org/10.1007/978-1-4612-2748-9</a></li>
<li>Deyle, E. R., &amp; Sugihara, G. (2011). Generalized theorems for nonlinear state space reconstruction. <em>PloS One</em>, 6(3), e18295. <a href="https://doi.org/10.1371/journal.pone.0018295" class="uri">https://doi.org/10.1371/journal.pone.0018295</a></li>
<li>Shalizi, C. R. (2003, May 12). Optimal Nonlinear Prediction of Random Fields on Networks. arXiv [math.PR]. Retrieved from <a href="http://arxiv.org/abs/math/0305160" class="uri">http://arxiv.org/abs/math/0305160</a></li>
<li>Shalizi, C. R., &amp; Moore, C. (2003, March 29). What Is a Macrostate? Subjective Observations and Objective Dynamics. arXiv [cond-mat.stat-mech]. Retrieved from <a href="http://arxiv.org/abs/cond-mat/0303625" class="uri">http://arxiv.org/abs/cond-mat/0303625</a></li>
<li>Wingate, D., &amp; Baveja, S. (2007). Exponential Family Predictive Representations of State. In J. Platt, D. Koller, Y. Singer, &amp; S. Roweis (Eds.), <em>Advances in Neural Information Processing Systems</em> (Vol. 20). Retrieved from <a href="https://proceedings.neurips.cc/paper_files/paper/2007/file/a9a1d5317a33ae8cef33961c34144f84-Paper.pdf" class="uri">https://proceedings.neurips.cc/paper_files/paper/2007/file/a9a1d5317a33ae8cef33961c34144f84-Paper.pdf</a></li>
</ul>
</section>
<section id="algorithms" class="level3">
<h3 class="anchored" data-anchor-id="algorithms">Algorithms</h3>
<ul>
<li>Ye, H., Deyle, E. R., Gilarranz, L. J., &amp; Sugihara, G. (2015). Distinguishing time-delayed causal interactions using convergent cross mapping. <em>Scientific Reports</em>, 5, 14750. <a href="https://doi.org/10.1038/srep14750" class="uri">https://doi.org/10.1038/srep14750</a></li>
<li>Le, T. D., Hoang, T., Li, J., Liu, L., Liu, H., &amp; Hu, S. (2019). A Fast PC Algorithm for High Dimensional Causal Discovery with Multi-Core PCs. <em>IEEE/ACM Transactions on Computational Biology and Bioinformatics / IEEE</em>, ACM, 16(5), 1483–1495. &lt;https://doi.org/10.1109/TCBB.2016.2591526</li>
<li>Langford, J., Salakhutdinov, R., &amp; Zhang, T. (2009, May 20). Learning Nonlinear Dynamic Models. arXiv [cs.AI]. Retrieved from <a href="http://arxiv.org/abs/0905.3369" class="uri">http://arxiv.org/abs/0905.3369</a></li>
<li>Littman, M. L., Sutton, R. S., &amp; Singh, S. (n.d.). Predictive Representations of State. In <em>NIPS 2001</em>. Retrieved from <a href="https://web.eecs.umich.edu/~baveja/Papers/psr.pdf" class="uri">https://web.eecs.umich.edu/~baveja/Papers/psr.pdf</a></li>
<li>Chalupka, K., Perona, P., &amp; Eberhardt, F. (2014, December 7). Visual Causal Feature Learning. arXiv [stat.ML]. Retrieved from <a href="http://arxiv.org/abs/1412.2309" class="uri">http://arxiv.org/abs/1412.2309</a></li>
<li>Hefny, A., Downey, C., &amp; Gordon, G. (2015, May 20). Supervised Learning for Dynamical System Learning. arXiv [stat.ML]. Retrieved from ,http://arxiv.org/abs/1505.05310&gt;</li>
<li>Subramanian, J., Sinha, A., Seraj, R., &amp; Mahajan, A. (2022). Approximate Information State for Approximate Planning and Reinforcement Learning in Partially Observed Systems. <em>Journal of Machine Learning Research: JMLR</em>, 23(12), 1–83. Retrieved from <a href="https://jmlr.org/papers/v23/20-1165.html" class="uri">https://jmlr.org/papers/v23/20-1165.html</a></li>
</ul>



</section>
</section>


 ]]></description>
  <category>math</category>
  <category>stats</category>
  <guid>https://viveks.me/notebooks/posts/state-space-reconstruction/index.html</guid>
  <pubDate>Sat, 10 Jun 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Deep Uncertainty and Subjective Probabilities</title>
  <link>https://viveks.me/notebooks/posts/deep-uncertainty-subjective-probability/index.html</link>
  <description><![CDATA[ 



<section id="the-problems-with-deep-uncertainty" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-problems-with-deep-uncertainty">The Problems With “Deep Uncertainty”</h2>
<p>Deep uncertainty is an extremely useful concept — it’s good to explicitly recognize that there is no consensus probability distribution as a red flag for the use of typical decision-making under uncertainty approaches. However, this can be taken to an extreme level: <em>because there is no consensus distribution, one should avoid the use of probabilities altogether</em>.</p>
<section id="people-impose-probabilities-anyway" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="people-impose-probabilities-anyway">People Impose Probabilities Anyway</h3>
<p>As <span class="citation" data-cites="Morgan2008-qg">Morgan &amp; Keith (2008)</span> discuss, people impose probabilities when they’re absent. The Representative Concentration Pathways (RCPs) are a good example: in the absence of guidance about probabilities, various papers have treated all of the RCPs as equally likely (equivalent to a uniform distribution), or focused on specific RCPs at the expense of others (implicitly assigning uneven probabilities). For example, many papers focus on RCP 8.5, the most extreme scenario: in some cases, this gives the highest climate-change-signal-to-noise ratio, but this actually appears to be a highly unlikely scenario, and without that contextualization, this can create biases in decision-making.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Morgan2008-qg" class="csl-entry">
Morgan, M. G., &amp; Keith, D. W. (2008). <span class="nocase">Improving the way we think about projecting future energy use and emissions of carbon dioxide</span>. <em>Clim. Change</em>, <em>90</em>, 189–215. <a href="https://doi.org/10.1007/s10584-008-9458-1">https://doi.org/10.1007/s10584-008-9458-1</a>
</div></div><div class="page-columns page-full"><p>This results in an epistemic hand-off from analyst to stakeholders, as stakeholders then have to impose their beliefs without guidance. It’s also unlikely<sup>1</sup> that the analyst shows how different beliefs This may be appropriate in some cases, when the local domain knowledge is stronger than the analyst’s knowledge, but may also result in political differences emerging by working backwards from desired outcomes<sup>2</sup>. This may be worsened by the Ellsberg Paradox when stakeholders are faced with deep uncertainty.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;But not impossible; a lot of the advanced analytics that accompany frameworks like Multi-Objective Robust Decision Making get at this</p></li><li id="fn2"><p><sup>2</sup>&nbsp;This can happen anyway, but we can make it more transparent</p></li></div></div>
</section>
</section>
<section id="embracing-subjective-probabilities" class="level2">
<h2 class="anchored" data-anchor-id="embracing-subjective-probabilities">Embracing Subjective Probabilities</h2>
<p>The alternative is to lean into subjectivity: based on the domain knowledge the expert has or has elicited, what probabilities would they assign and what does that mean about the decision space? Ideally, the analyst doesn’t stop there and looks at how different assignments of probability influence the decision analysis. This would make both a forwards (probability -&gt; outcome) and backwards (outcomes -&gt; probability) process more transparent.</p>
</section>
<section id="things-i-need-to-think-about-more" class="level2">
<h2 class="anchored" data-anchor-id="things-i-need-to-think-about-more">Things I Need To Think About More</h2>
<ul>
<li>How seriously should we take the epistemic-ethical implications of an analyst refusing to look at probabilities? When is it appropriate?</li>
<li>Communicating uncertainties is hard. Is it worse when we’re up front about these being subjective?</li>
</ul>
</section>
<section id="see-also" class="level2">
<h2 class="anchored" data-anchor-id="see-also">See Also</h2>
<p><a href="../robustness/">Robustness</a></p>
</section>
<section id="relevant-reading" class="level2">
<h2 class="anchored" data-anchor-id="relevant-reading">Relevant Reading</h2>
<ul>
<li>Morgan, M. G., &amp; Keith, D. W. (2008). Improving the way we think about projecting future energy use and emissions of carbon dioxide. <em>Climatic Change</em>, 90(3), 189–215. <a href="https://doi.org/10.1007/s10584-008-9458-1" class="uri">https://doi.org/10.1007/s10584-008-9458-1</a></li>
<li>Doss-Gollin, J., &amp; Keller, K. (2023). A subjective Bayesian framework for synthesizing deep uncertainties in climate risk management. <em>Earth’s Future</em>, 11(1), e2022EF003044. <a href="https://doi.org/10.1029/2022ef003044" class="uri">https://doi.org/10.1029/2022ef003044</a></li>
<li>Katzav, J., Thompson, E. L., Risbey, J., Stainforth, D. A., Bradley, S., &amp; Frisch, M. (2021). On the appropriate and inappropriate uses of probability distributions in climate projections and some alternatives. <em>Climatic Change</em>, 169(1), 15. <a href="https://doi.org/10.1007/s10584-021-03267-x" class="uri">https://doi.org/10.1007/s10584-021-03267-x</a></li>
</ul>



</section>


 ]]></description>
  <category>uncertainty</category>
  <category>decision-making</category>
  <category>ethics</category>
  <guid>https://viveks.me/notebooks/posts/deep-uncertainty-subjective-probability/index.html</guid>
  <pubDate>Fri, 09 Jun 2023 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
