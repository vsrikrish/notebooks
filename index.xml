<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Notebooks</title>
<link>https://viveks.me/notebooks/index.html</link>
<atom:link href="https://viveks.me/notebooks/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.3.361</generator>
<lastBuildDate>Sun, 11 Jun 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>Model Discrepancy</title>
  <link>https://viveks.me/notebooks/posts/model-discrepancy/index.html</link>
  <description><![CDATA[ 



<p>Model discrepancy refers to systematic mismatches between model and data. This is conceptually different from observation error (which is typically assumed to be white noise), though both combine to produce the model residuals. When discrepancy is assumed to be normal, non-identifiability makes it challenging to separate from observation error, so these are usually lumped together, but this is usually a poor choice in environmental application.</p>
<section id="relevant-reading" class="level2">
<h2 class="anchored" data-anchor-id="relevant-reading">Relevant Reading</h2>
<ul>
<li>Kennedy, M. C., &amp; O’Hagan, A. (2001). Bayesian calibration of computer models. <em>Journal of the Royal Statistical Society. Series B, Statistical Methodology</em>, 63(3), 425–464. <a href="https://doi.org/10.1111/1467-9868.00294" class="uri">https://doi.org/10.1111/1467-9868.00294</a></li>
<li>Brynjarsdóttir, J., &amp; OʼHagan, A. (2014). Learning about physical parameters: the importance of model discrepancy. <em>Inverse Problems</em>, 30(11), 114007. <a href="https://doi.org/10.1088/0266-5611/30/11/114007" class="uri">https://doi.org/10.1088/0266-5611/30/11/114007</a></li>
<li>Jiang, B., Wu, T.-Y., &amp; Wong, W. H. (2018). Approximate Bayesian Computation with Kullback-Leibler Divergence as Data Discrepancy. In A. Storkey &amp; F. Perez-Cruz (Eds.), <em>Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics</em> (Vol. 84, pp.&nbsp;1711–1721). Lanzarote, Spain: PMLR. Retrieved from <a href="https://proceedings.mlr.press/v84/jiang18a.html" class="uri">https://proceedings.mlr.press/v84/jiang18a.html</a></li>
<li>Gardner, P., Rogers, T. J., Lord, C., &amp; Barthorpe, R. J. (2019). Learning of model discrepancy for structural dynamics applications using Bayesian history matching. <em>Journal of Physics. Conference Series</em>, 1264(1), 012052. <a href="https://doi.org/10.1088/1742-6596/1264/1/012052" class="uri">https://doi.org/10.1088/1742-6596/1264/1/012052</a></li>
</ul>


</section>

 ]]></description>
  <category>stats</category>
  <guid>https://viveks.me/notebooks/posts/model-discrepancy/index.html</guid>
  <pubDate>Sun, 11 Jun 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Robustness</title>
  <link>https://viveks.me/notebooks/posts/robustness/index.html</link>
  <description><![CDATA[ 



<p>Robustness is a vaguely defined term. There are really two different, though related, types of robustness, as the term is commonly used:</p>
<ol type="1">
<li>Robustness of a decision, <em>i.e.</em> how well does a particular decision perform under alternative states of the world (SOWs)?</li>
<li>Robustness of model insights to researcher degrees of freedom/forking paths.</li>
</ol>
<p>The former is the focus in this notebook, though the latter is often more interesting and difficult to quantify; often one has to link back to the original system and ensure that the model was adequate (not <em>valid</em>, as commonly used) and that the insights make sense <span class="citation" data-cites="Oreskes1994-br">(Oreskes et al., 1994)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Oreskes1994-br" class="csl-entry">
Oreskes, N., Shrader-Frechette, K., &amp; Belitz, K. (1994). <span class="nocase">Verification, validation, and confirmation of numerical models in the earth sciences</span>. <em>Science</em>, <em>263</em>, 641–646. <a href="https://doi.org/10.1126/science.263.5147.641">https://doi.org/10.1126/science.263.5147.641</a>
</div></div><div class="page-columns page-full"><p>Assessing the robustness of a decision is best done as a summary of a type of sensitivity: pick a solution that seems acceptable under some decision-making method, and then stress-test it to make sure it performs adequately across scenarios<sup>1</sup>.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;Picking the threshold for adequate peformance is another issue…</p></li></div></div>
<section id="satisfycing" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="satisfycing">Satisfycing</h2>
<p>Satisfycing measures how often a particular performance threshold is reached across the range of states of the world. In other words, assign a 0-1 loss over the tolerable domain <img src="https://latex.codecogs.com/png.latex?D%20%5Csubset%20X">:</p>
<p><img src="https://latex.codecogs.com/png.latex?L(%5Cmathbf%7Bx%7D)%20=%20%5Cbegin%7Bcases%7D0%20&amp;%20%5Cmathbf%7Bx%7D%20%5Cin%20D%20%5C%5C%201%20&amp;%20%5Cmathbf%7Bx%7D%20%5Cnotin%20D.%5Cend%7Bcases%7D"></p>
<p>Then the satisfycing score is</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cint_X%20L(%5Cmathbf%7Bx%7D)%20p(x)%20dx%20=%20%5Cint_D%20p(x)%20dx."></p>
<section id="sensitivity-of-satisfycing-score-to-probabilities" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sensitivity-of-satisfycing-score-to-probabilities">Sensitivity of Satisfycing Score to Probabilities</h3>
<div class="page-columns page-full"><p>This makes the score sensitive to the probability distribution <img src="https://latex.codecogs.com/png.latex?p"> and the tolerable domain <img src="https://latex.codecogs.com/png.latex?D">. As a result, even if the tolerable threshold is well-defined<sup>2</sup> this begs the question somewhat, as the robustness scores will depend on how frequently poorly-performing scenarios are sampled. A uniform distribution may be the worst option of all<sup>3</sup>. A good sensitivity analysis can diagnose this type of issue, but may not be reflected in a satisfycing approach. <span class="citation" data-cites="Quinn2020-cr">Quinn et al. (2020)</span> shows that this notion of robustness is not itself robust to different scenario samples; this is related to fundamental issues with “Robust Bayes” <span class="citation" data-cites="Gelman2006-eh">(Gelman, 2006)</span>.</p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;Which seems unlikely across stakeholders, but let’s grant that for now…</p></li><li id="fn3"><p><sup>3</sup>&nbsp;The principle of insufficient reason is only one way to express ignorance, and makes no sense for subjective probabilities <span class="citation" data-cites="Kass1996-ro">(Kass &amp; Wasserman, 1996)</span>.</p><div id="ref-Kass1996-ro" class="csl-entry">
Kass, R. E., &amp; Wasserman, L. (1996). <span class="nocase">The selection of prior distributions by formal rules</span>. <em>J. Am. Stat. Assoc.</em>, <em>91</em>, 1343–1370. <a href="https://doi.org/10.1080/01621459.1996.10477003">https://doi.org/10.1080/01621459.1996.10477003</a>
</div></li><div id="ref-Quinn2020-cr" class="csl-entry">
Quinn, J. D., Hadjimichael, A., Reed, P. M., &amp; Steinschneider, S. (2020). <span class="nocase">Can exploratory modeling of water scarcity vulnerabilities and robustness be scenario neutral?</span> <em>Earth’s Future</em>, <em>8</em>, e2020EF001650. <a href="https://doi.org/10.1029/2020EF001650">https://doi.org/10.1029/2020EF001650</a>
</div><div id="ref-Gelman2006-eh" class="csl-entry">
Gelman, A. (2006). <span class="nocase">The boxer, the wrestler, and the coin flip: A paradox of robust bayesian inference and belief functions</span>. <em>Am. Stat.</em>, <em>60</em>, 146–150. <a href="https://doi.org/10.1198/000313006X106190">https://doi.org/10.1198/000313006X106190</a>
</div></div></div>
<p>For analyzing a single decision or a set of decisions, this approach is likely fine to understand the sensitivity of the decision’s adequacy to mis-parameterization. Things get worse when trying to use robustness as an objective for the decision analysis, particularly when probabilities are diffuse or ill-characterized, as obtaining the state(s) of the world used in the analysis is itself fraught and/or relies on subjective probabilities anyway: the resulting decision is itself likely highly sensitive to any number of decisions in the problem setup, and now we’re back at the other kind of robustness.</p>
</section>
<section id="model-discrepancy" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="model-discrepancy">Model Discrepancy</h3>
<div class="page-columns page-full"><p>There’s also another, maybe more fundamental issue: <a href="../model-discrepancy/">model discrepancy</a>. If your performance threshold is <img src="https://latex.codecogs.com/png.latex?%5Ctau"> and the model prediction for a state of the world <img src="https://latex.codecogs.com/png.latex?s"> is <img src="https://latex.codecogs.com/png.latex?F(s)">, you want to know if <img src="https://latex.codecogs.com/png.latex?f(s)%20%3E%20%5Ctau">. But if <img src="https://latex.codecogs.com/png.latex?F"> has a discrepancy <img src="https://latex.codecogs.com/png.latex?%5Czeta(s)">, you could mis-score <img src="https://latex.codecogs.com/png.latex?s"> if <img src="https://latex.codecogs.com/png.latex?%5Czeta"> moves you to the other side of <img src="https://latex.codecogs.com/png.latex?%5Ctau">, with potentially important implications<sup>4</sup></p><div class="no-row-height column-margin column-container"><li id="fn4"><p><sup>4</sup>&nbsp;This isn’t unique to the robustness setting, either: it applies to any model-based decision analysis with a 0-1 loss. For example, we should talk about this more in the context of pathways to zero emissions.</p></li></div></div>
</section>
</section>
<section id="regret" class="level2">
<h2 class="anchored" data-anchor-id="regret">Regret</h2>
<p>Regret is fine and reasonably sensible: it’s a Bayesian score with a loss of the following type:</p>
<p><img src="https://latex.codecogs.com/png.latex?L(%5Cmathbf%7Bx%7D)%20=%20%5Cbegin%7Bcases%7D0%20&amp;%20if%20%5Cmathbf%7Bx%7D%20%5Cin%20D%20%5C%5C%20R(%5C%7C%20%5Cmathbf%7Bx%7D%20-%20%5Ctau%20%5C%7C)%20&amp;%20if%20%5Cmathbf%7Bx%7D%20%5Cnotin%20D,%5Cend%7Bcases%7D"> where <img src="https://latex.codecogs.com/png.latex?%5C%7C%20%5Ccdot%20%5C%7C"> is some metric over outcomes. Nothing too interesting, and likely leads to more sensible rankings than satisfycing when they differ. I also think it’s preferable for decision-making to losses which are more mathematical constructs than decision-relevant, like mean or logarithmic losses. For certain choices of <img src="https://latex.codecogs.com/png.latex?L">, this also helps smooth out the model discrepancy issue, since you can make the loss within some neighborhood of the boundary of <img src="https://latex.codecogs.com/png.latex?D"> positive as a buffer and adjust <img src="https://latex.codecogs.com/png.latex?R"> to smooth the transition from <img src="https://latex.codecogs.com/png.latex?D"> to a high-regret region. It might be interesting to explore this in a quick paper, maybe for the shallow lake problem or coastal flood risk.</p>
</section>
<section id="see-also" class="level2">
<h2 class="anchored" data-anchor-id="see-also">See Also</h2>
<p><a href="../deep-uncertainty-subjective-probability/">Deep Uncertainty and Subjective Probabilities</a></p>
</section>
<section id="relevant-reading" class="level2">
<h2 class="anchored" data-anchor-id="relevant-reading">Relevant Reading</h2>
<ul>
<li>Herman, J. D., Reed, P. M., Zeff, H. B., &amp; Characklis, G. W. (2015). How should robustness be defined for water systems planning under change? <em>Journal of Water Resources Planning and Management</em>, 141(10), 04015012. <a href="https://doi.org/10.1061/(ASCE)WR.1943-5452.0000509" class="uri">https://doi.org/10.1061/(ASCE)WR.1943-5452.0000509</a></li>
<li>Giuliani, M., &amp; Castelletti, A. (4/2016). Is robustness really robust? How different definitions of robustness impact decision-making under climate change. <em>Climatic Change</em>, 135(3–4), 409–424. <a href="https://doi.org/10.1007/s10584-015-1586-9" class="uri">https://doi.org/10.1007/s10584-015-1586-9</a></li>
<li>McPhail, C., Maier, H. R., Kwakkel, J., Giuliani, M., &amp; Westra, S. (2018). Robustness Metrics: How Are They Calculated, When Should They Be Used and Why Do They Give Different Results? <em>Earth’s Future</em>, 6(2)). <a href="https://doi.org/10.1002/2017EF000649" class="uri">https://doi.org/10.1002/2017EF000649</a></li>
<li>McPhail, C., Maier, H. R., Westra, S., Kwakkel, J. H., &amp; Linden, L. (09/2020). Impact of scenario selection on robustness. <em>Water Resources Research</em>, 56(9). <a href="https://doi.org/10.1029/2019WR026515" class="uri">https://doi.org/10.1029/2019WR026515</a></li>
<li>Quinn, J. D., Hadjimichael, A., Reed, P. M., &amp; Steinschneider, S. (2020). Can exploratory modeling of water scarcity vulnerabilities and robustness be scenario neutral? <em>Earth’s Future</em>, 8(11), e2020EF001650. <a href="https://doi.org/10.1029/2020EF001650" class="uri">https://doi.org/10.1029/2020EF001650</a></li>
</ul>



</section>


 ]]></description>
  <category>uncertainty</category>
  <category>decision-making</category>
  <guid>https://viveks.me/notebooks/posts/robustness/index.html</guid>
  <pubDate>Sat, 10 Jun 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>State-Space Reconstruction</title>
  <link>https://viveks.me/notebooks/posts/state-space-reconstruction/index.html</link>
  <description><![CDATA[ 



<p>Given a time series that we assume came from a dynamical system, can we reconstruct the state space of the system from the observations? This is complicated by a few features of chaotic or noisy systems.</p>
<section id="setup-and-theorem" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="setup-and-theorem">Setup and Theorem</h2>
<div class="page-columns page-full"><p>Suppose we have a <em>deterministic</em> dynamical system with state <img src="https://latex.codecogs.com/png.latex?z(t)"> on a smooth manifold of dimension <img src="https://latex.codecogs.com/png.latex?m">. Our observations are <img src="https://latex.codecogs.com/png.latex?x(t)%20=%20g(z(t))"><sup>1</sup>.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;often <img src="https://latex.codecogs.com/png.latex?g(y)%20=%20y%20+%20%5Cvarepsilon_t">, where <img src="https://latex.codecogs.com/png.latex?%5Cvarepsilon_t"> is some noise process, but this can be more complex.</p></li></div></div>
<p>For a time horizon <img src="https://latex.codecogs.com/png.latex?%5Ctau%20%3C%20%5Cinfty"> and a positive integer <img src="https://latex.codecogs.com/png.latex?k">, set <img src="https://latex.codecogs.com/png.latex?s(t)%20=%20(x(t),%20x(t%20-%20%5Ctau),%20x(t%20-%202%5Ctau),%20%5Cldots,%20x(t%20-%20(k-1)%20%5Ctau))."> It turns out <span class="citation" data-cites="Takens1981-gq">(Takens., 1981)</span> that if <img src="https://latex.codecogs.com/png.latex?k%20%5Cgeq%202m+1">, then <img src="https://latex.codecogs.com/png.latex?z(t)%20=%20%5Cphi(s(t))"> for some diffeomorphism <img src="https://latex.codecogs.com/png.latex?%5Cphi">.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Takens1981-gq" class="csl-entry">
Takens., F. (1981). <span class="nocase">Detecting strange attractors in turbulence</span>. In D. A. Rand &amp; L. S. Young (Eds.), <em><span class="nocase"><em>Symposium on Dynamical Systems and Turbulence (</em>Springer Lecture Notes in Mathematics vol. 898)</span></em> (pp. 366–381). Berlin, Germany: Springer. Retrieved from <a href="https://www.crcv.ucf.edu/gauss/info/Takens.pdf">https://www.crcv.ucf.edu/gauss/info/Takens.pdf</a>
</div></div><div class="page-columns page-full"><p>A nice application of this is in the context of climate change. A common tendency along among certain climate-change skeptics<sup>2</sup> was to use Granger causality to claim that warming causes CO<sub>2</sub> increases. This use violates the relevant assumptions of Granger causality, namely that there is no confounding causal influence on both time series<sup>3</sup>. Instead, <span class="citation" data-cites="Van_Nes2015-ua">Nes et al. (2015)</span> show using Takens’ theorem that we get the expected feedbacks on the right time scales.</p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;Who know only enough to make these mistakes but not recognize them!</p></li><li id="fn3"><p><sup>3</sup>&nbsp;In this case, Milankovitch cycles but we also know that the relationship between temperature and CO<sub>2</sub> changes depending on the time scale of interest</p></li><div id="ref-Van_Nes2015-ua" class="csl-entry">
Nes, E. H. van, Scheffer, M., Brovkin, V., Lenton, T. M., Ye, H., Deyle, E., &amp; Sugihara, G. (2015). Causal feedbacks in climate change. <em>Nat. Clim. Chang.</em>, <em>5</em>(5), 445–448. <a href="https://doi.org/10.1038/nclimate2568">https://doi.org/10.1038/nclimate2568</a>
</div></div></div>
</section>
<section id="main-interest" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="main-interest">Main Interest</h2>
<div class="page-columns page-full"><p>My main interest is in getting this to work on multi-sector networks: can we reconstruct the state trajectory of a system of many state variables given a simulation? Using an ensemble of simulations would allow us to look for tipping points or teleconnections or track the propagation of shocks<sup>4</sup>. The complications in making this tractable are stochasticity<sup>5</sup> and dimensionality<sup>6</sup>, but maybe looking at network properties can reduce the dimensionality. Maybe this can be done with the PC algorithm.</p><div class="no-row-height column-margin column-container"><li id="fn4"><p><sup>4</sup>&nbsp;“George Box has [almost] said”The only way to find out what will happen when a complex system is disturbed is to disturb the system, not merely to observe it passively.” These words of caution about “natural experiments” are uncomfortably strong. Yet in today’s world we see no alternative to accepting them as, if anything, too weak.” - Mosteller &amp; Tukey (1977)</p></li><li id="fn5"><p><sup>5</sup>&nbsp;We would need to reconstruct a Markov process</p></li><li id="fn6"><p><sup>6</sup>&nbsp;Finding the relevant DAG is expensive.</p></li></div></div>
</section>
<section id="things-i-need-to-think-about-more" class="level2">
<h2 class="anchored" data-anchor-id="things-i-need-to-think-about-more">Things I Need To Think About More</h2>
<ul>
<li>Methods for reconstructing networks from potentially noisy simulations</li>
<li>Use of network invariants for dimension-reduction. Maybe topological data analysis has some application?</li>
</ul>
</section>
<section id="relevant-reading" class="level2">
<h2 class="anchored" data-anchor-id="relevant-reading">Relevant Reading</h2>
<section id="reconstruction" class="level3">
<h3 class="anchored" data-anchor-id="reconstruction">Reconstruction</h3>
<ul>
<li>Takens., F. (1981). Detecting strange attractors in turbulence. In D. A. Rand &amp; L. S. Young (Eds.), <em>Symposium on Dynamical Systems and Turbulence</em> (Springer Lecture Notes in Mathematics vol.&nbsp;898) (pp.&nbsp;366–381). Berlin, Germany: Springer.</li>
<li>Stark, J., Broomhead, D. S., Davies, M. E., &amp; Huke, J. (1997). Takens embedding theorems for forced and stochastic systems. <em>Nonlinear Analysis, Theory, Methods &amp; Applications</em>, 30(8), 5303–5314. <a href="https://doi.org/10.1016/S0362-546X(96)00149-6" class="uri">https://doi.org/10.1016/S0362-546X(96)00149-6</a></li>
<li>Robinson, J. C. (2005). A topological delay embedding theorem for infinite-dimensional dynamical systems. <em>Nonlinearity</em>, 18(5), 2135. <a href="https://doi.org/10.1088/0951-7715/18/5/013" class="uri">https://doi.org/10.1088/0951-7715/18/5/013</a></li>
<li>Garcia, S. P., &amp; Almeida, J. S. (2006, September 12). Multivariate phase space reconstruction by nearest neighbor embedding with different time delays. arXiv [nlin.CD]. Retrieved from <a href="http://arxiv.org/abs/nlin/0609029" class="uri">http://arxiv.org/abs/nlin/0609029</a></li>
<li>Spirtes, P., Glymour, C., &amp; Scheines, R. (1993). Causation, Prediction, and Search. New York, NY: Springer. <a href="https://doi.org/10.1007/978-1-4612-2748-9" class="uri">https://doi.org/10.1007/978-1-4612-2748-9</a></li>
<li>Deyle, E. R., &amp; Sugihara, G. (2011). Generalized theorems for nonlinear state space reconstruction. <em>PloS One</em>, 6(3), e18295. <a href="https://doi.org/10.1371/journal.pone.0018295" class="uri">https://doi.org/10.1371/journal.pone.0018295</a></li>
<li>Shalizi, C. R. (2003, May 12). Optimal Nonlinear Prediction of Random Fields on Networks. arXiv [math.PR]. Retrieved from <a href="http://arxiv.org/abs/math/0305160" class="uri">http://arxiv.org/abs/math/0305160</a></li>
<li>Shalizi, C. R., &amp; Moore, C. (2003, March 29). What Is a Macrostate? Subjective Observations and Objective Dynamics. arXiv [cond-mat.stat-mech]. Retrieved from <a href="http://arxiv.org/abs/cond-mat/0303625" class="uri">http://arxiv.org/abs/cond-mat/0303625</a></li>
<li>Wingate, D., &amp; Baveja, S. (2007). Exponential Family Predictive Representations of State. In J. Platt, D. Koller, Y. Singer, &amp; S. Roweis (Eds.), <em>Advances in Neural Information Processing Systems</em> (Vol. 20). Retrieved from <a href="https://proceedings.neurips.cc/paper_files/paper/2007/file/a9a1d5317a33ae8cef33961c34144f84-Paper.pdf" class="uri">https://proceedings.neurips.cc/paper_files/paper/2007/file/a9a1d5317a33ae8cef33961c34144f84-Paper.pdf</a></li>
</ul>
</section>
<section id="algorithms" class="level3">
<h3 class="anchored" data-anchor-id="algorithms">Algorithms</h3>
<ul>
<li>Ye, H., Deyle, E. R., Gilarranz, L. J., &amp; Sugihara, G. (2015). Distinguishing time-delayed causal interactions using convergent cross mapping. <em>Scientific Reports</em>, 5, 14750. <a href="https://doi.org/10.1038/srep14750" class="uri">https://doi.org/10.1038/srep14750</a></li>
<li>Le, T. D., Hoang, T., Li, J., Liu, L., Liu, H., &amp; Hu, S. (2019). A Fast PC Algorithm for High Dimensional Causal Discovery with Multi-Core PCs. <em>IEEE/ACM Transactions on Computational Biology and Bioinformatics / IEEE</em>, ACM, 16(5), 1483–1495. &lt;https://doi.org/10.1109/TCBB.2016.2591526</li>
<li>Langford, J., Salakhutdinov, R., &amp; Zhang, T. (2009, May 20). Learning Nonlinear Dynamic Models. arXiv [cs.AI]. Retrieved from <a href="http://arxiv.org/abs/0905.3369" class="uri">http://arxiv.org/abs/0905.3369</a></li>
<li>Littman, M. L., Sutton, R. S., &amp; Singh, S. (n.d.). Predictive Representations of State. In <em>NIPS 2001</em>. Retrieved from <a href="https://web.eecs.umich.edu/~baveja/Papers/psr.pdf" class="uri">https://web.eecs.umich.edu/~baveja/Papers/psr.pdf</a></li>
<li>Chalupka, K., Perona, P., &amp; Eberhardt, F. (2014, December 7). Visual Causal Feature Learning. arXiv [stat.ML]. Retrieved from <a href="http://arxiv.org/abs/1412.2309" class="uri">http://arxiv.org/abs/1412.2309</a></li>
<li>Hefny, A., Downey, C., &amp; Gordon, G. (2015, May 20). Supervised Learning for Dynamical System Learning. arXiv [stat.ML]. Retrieved from ,http://arxiv.org/abs/1505.05310&gt;</li>
<li>Subramanian, J., Sinha, A., Seraj, R., &amp; Mahajan, A. (2022). Approximate Information State for Approximate Planning and Reinforcement Learning in Partially Observed Systems. <em>Journal of Machine Learning Research: JMLR</em>, 23(12), 1–83. Retrieved from <a href="https://jmlr.org/papers/v23/20-1165.html" class="uri">https://jmlr.org/papers/v23/20-1165.html</a></li>
</ul>



</section>
</section>


 ]]></description>
  <category>math</category>
  <category>stats</category>
  <guid>https://viveks.me/notebooks/posts/state-space-reconstruction/index.html</guid>
  <pubDate>Sat, 10 Jun 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Deep Uncertainty and Subjective Probabilities</title>
  <link>https://viveks.me/notebooks/posts/deep-uncertainty-subjective-probability/index.html</link>
  <description><![CDATA[ 



<section id="the-problems-with-deep-uncertainty" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-problems-with-deep-uncertainty">The Problems With “Deep Uncertainty”</h2>
<p>Deep uncertainty is an extremely useful concept — it’s good to explicitly recognize that there is no consensus probability distribution as a red flag for the use of typical decision-making under uncertainty approaches. However, this can be taken to an extreme level: <em>because there is no consensus distribution, one should avoid the use of probabilities altogether</em>.</p>
<section id="people-impose-probabilities-anyway" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="people-impose-probabilities-anyway">People Impose Probabilities Anyway</h3>
<p>As <span class="citation" data-cites="Morgan2008-qg">Morgan &amp; Keith (2008)</span> discuss, people impose probabilities when they’re absent. The Representative Concentration Pathways (RCPs) are a good example: in the absence of guidance about probabilities, various papers have treated all of the RCPs as equally likely (equivalent to a uniform distribution), or focused on specific RCPs at the expense of others (implicitly assigning uneven probabilities). For example, many papers focus on RCP 8.5, the most extreme scenario: in some cases, this gives the highest climate-change-signal-to-noise ratio, but this actually appears to be a highly unlikely scenario, and without that contextualization, this can create biases in decision-making.</p>
<div class="no-row-height column-margin column-container"><div id="ref-Morgan2008-qg" class="csl-entry">
Morgan, M. G., &amp; Keith, D. W. (2008). <span class="nocase">Improving the way we think about projecting future energy use and emissions of carbon dioxide</span>. <em>Clim. Change</em>, <em>90</em>, 189–215. <a href="https://doi.org/10.1007/s10584-008-9458-1">https://doi.org/10.1007/s10584-008-9458-1</a>
</div></div><div class="page-columns page-full"><p>This results in an epistemic hand-off from analyst to stakeholders, as stakeholders then have to impose their beliefs without guidance. It’s also unlikely<sup>1</sup> that the analyst shows how different beliefs This may be appropriate in some cases, when the local domain knowledge is stronger than the analyst’s knowledge, but may also result in political differences emerging by working backwards from desired outcomes<sup>2</sup>. This may be worsened by the Ellsberg Paradox when stakeholders are faced with deep uncertainty.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;But not impossible; a lot of the advanced analytics that accompany frameworks like Multi-Objective Robust Decision Making get at this</p></li><li id="fn2"><p><sup>2</sup>&nbsp;This can happen anyway, but we can make it more transparent</p></li></div></div>
</section>
</section>
<section id="embracing-subjective-probabilities" class="level2">
<h2 class="anchored" data-anchor-id="embracing-subjective-probabilities">Embracing Subjective Probabilities</h2>
<p>The alternative is to lean into subjectivity: based on the domain knowledge the expert has or has elicited, what probabilities would they assign and what does that mean about the decision space? Ideally, the analyst doesn’t stop there and looks at how different assignments of probability influence the decision analysis. This would make both a forwards (probability -&gt; outcome) and backwards (outcomes -&gt; probability) process more transparent.</p>
</section>
<section id="things-i-need-to-think-about-more" class="level2">
<h2 class="anchored" data-anchor-id="things-i-need-to-think-about-more">Things I Need To Think About More</h2>
<ul>
<li>How seriously should we take the epistemic-ethical implications of an analyst refusing to look at probabilities? When is it appropriate?</li>
<li>Communicating uncertainties is hard. Is it worse when we’re up front about these being subjective?</li>
</ul>
</section>
<section id="see-also" class="level2">
<h2 class="anchored" data-anchor-id="see-also">See Also</h2>
<p><a href="../robustness/">Robustness</a></p>
</section>
<section id="relevant-reading" class="level2">
<h2 class="anchored" data-anchor-id="relevant-reading">Relevant Reading</h2>
<ul>
<li>Morgan, M. G., &amp; Keith, D. W. (2008). Improving the way we think about projecting future energy use and emissions of carbon dioxide. <em>Climatic Change</em>, 90(3), 189–215. <a href="https://doi.org/10.1007/s10584-008-9458-1" class="uri">https://doi.org/10.1007/s10584-008-9458-1</a></li>
<li>Doss-Gollin, J., &amp; Keller, K. (2023). A subjective Bayesian framework for synthesizing deep uncertainties in climate risk management. <em>Earth’s Future</em>, 11(1), e2022EF003044. <a href="https://doi.org/10.1029/2022ef003044" class="uri">https://doi.org/10.1029/2022ef003044</a></li>
<li>Katzav, J., Thompson, E. L., Risbey, J., Stainforth, D. A., Bradley, S., &amp; Frisch, M. (2021). On the appropriate and inappropriate uses of probability distributions in climate projections and some alternatives. <em>Climatic Change</em>, 169(1), 15. <a href="https://doi.org/10.1007/s10584-021-03267-x" class="uri">https://doi.org/10.1007/s10584-021-03267-x</a></li>
</ul>



</section>


 ]]></description>
  <category>uncertainty</category>
  <category>decision-making</category>
  <category>ethics</category>
  <guid>https://viveks.me/notebooks/posts/deep-uncertainty-subjective-probability/index.html</guid>
  <pubDate>Fri, 09 Jun 2023 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
