[
  {
    "objectID": "posts/state-space-reconstruction/index.html",
    "href": "posts/state-space-reconstruction/index.html",
    "title": "State-Space Reconstruction",
    "section": "",
    "text": "Given a time series that we assume came from a dynamical system, can we reconstruct the state space of the system from the observations? This is complicated by a few features of chaotic or noisy systems."
  },
  {
    "objectID": "posts/state-space-reconstruction/index.html#setup-and-theorem",
    "href": "posts/state-space-reconstruction/index.html#setup-and-theorem",
    "title": "State-Space Reconstruction",
    "section": "Setup and Theorem",
    "text": "Setup and Theorem\nSuppose we have a deterministic dynamical system with state \\(z(t)\\) on a smooth manifold of dimension \\(m\\). Our observations are \\(x(t) = g(z(t))\\)1.1 often \\(g(y) = y + \\varepsilon_t\\), where \\(\\varepsilon_t\\) is some noise process, but this can be more complex.\nFor a time horizon \\(\\tau &lt; \\infty\\) and a positive integer \\(k\\), set \\[s(t) = (x(t), x(t - \\tau), x(t - 2\\tau), \\ldots, x(t - (k-1) \\tau)).\\] It turns out (Takens., 1981) that if \\(k \\geq 2m+1\\), then \\[z(t) = \\phi(s(t))\\] for some diffeomorphism \\(\\phi\\).\nA nice application of this is in the context of climate change. A common tendency along among certain climate-change skeptics2 was to use Granger causality to claim that warming causes CO2 increases. This use violates the relevant assumptions of Granger causality, namely that there is no confounding causal influence on both time series3. Instead, Nes et al. (2015) show using Takens’ theorem that we get the expected feedbacks on the right time scales.2 Who know only enough to make these mistakes but not recognize them!3 In this case, Milankovitch cycles but we also know that the relationship between temperature and CO2 changes depending on the time scale of interest"
  },
  {
    "objectID": "posts/state-space-reconstruction/index.html#main-interest",
    "href": "posts/state-space-reconstruction/index.html#main-interest",
    "title": "State-Space Reconstruction",
    "section": "Main Interest",
    "text": "Main Interest\nMy main interest is in getting this to work on multi-sector networks: can we reconstruct the state trajectory of a system of many state variables given a simulation? Using an ensemble of simulations would allow us to look for tipping points or teleconnections or track the propagation of shocks4. The complications in making this tractable are stochasticity5 and dimensionality6, but maybe looking at network properties can reduce the dimensionality. Maybe this can be done with the PC algorithm.4 “George Box has [almost] said”The only way to find out what will happen when a complex system is disturbed is to disturb the system, not merely to observe it passively.” These words of caution about “natural experiments” are uncomfortably strong. Yet in today’s world we see no alternative to accepting them as, if anything, too weak.” - Mosteller & Tukey (1977)5 We would need to reconstruct a Markov process6 Finding the relevant DAG is expensive."
  },
  {
    "objectID": "posts/state-space-reconstruction/index.html#things-i-need-to-think-about-more",
    "href": "posts/state-space-reconstruction/index.html#things-i-need-to-think-about-more",
    "title": "State-Space Reconstruction",
    "section": "Things I Need To Think About More",
    "text": "Things I Need To Think About More\n\nMethods for reconstructing networks from potentially noisy simulations\nUse of network invariants for dimension-reduction. Maybe topological data analysis has some application?"
  },
  {
    "objectID": "posts/state-space-reconstruction/index.html#relevant-reading",
    "href": "posts/state-space-reconstruction/index.html#relevant-reading",
    "title": "State-Space Reconstruction",
    "section": "Relevant Reading",
    "text": "Relevant Reading\n\nReconstruction\n\nTakens., F. (1981). Detecting strange attractors in turbulence. In D. A. Rand & L. S. Young (Eds.), Symposium on Dynamical Systems and Turbulence (Springer Lecture Notes in Mathematics vol. 898) (pp. 366–381). Berlin, Germany: Springer.\nStark, J., Broomhead, D. S., Davies, M. E., & Huke, J. (1997). Takens embedding theorems for forced and stochastic systems. Nonlinear Analysis, Theory, Methods & Applications, 30(8), 5303–5314. https://doi.org/10.1016/S0362-546X(96)00149-6\nRobinson, J. C. (2005). A topological delay embedding theorem for infinite-dimensional dynamical systems. Nonlinearity, 18(5), 2135. https://doi.org/10.1088/0951-7715/18/5/013\nGarcia, S. P., & Almeida, J. S. (2006, September 12). Multivariate phase space reconstruction by nearest neighbor embedding with different time delays. arXiv [nlin.CD]. Retrieved from http://arxiv.org/abs/nlin/0609029\nSpirtes, P., Glymour, C., & Scheines, R. (1993). Causation, Prediction, and Search. New York, NY: Springer. https://doi.org/10.1007/978-1-4612-2748-9\nDeyle, E. R., & Sugihara, G. (2011). Generalized theorems for nonlinear state space reconstruction. PloS One, 6(3), e18295. https://doi.org/10.1371/journal.pone.0018295\nShalizi, C. R. (2003, May 12). Optimal Nonlinear Prediction of Random Fields on Networks. arXiv [math.PR]. Retrieved from http://arxiv.org/abs/math/0305160\nShalizi, C. R., & Moore, C. (2003, March 29). What Is a Macrostate? Subjective Observations and Objective Dynamics. arXiv [cond-mat.stat-mech]. Retrieved from http://arxiv.org/abs/cond-mat/0303625\nWingate, D., & Baveja, S. (2007). Exponential Family Predictive Representations of State. In J. Platt, D. Koller, Y. Singer, & S. Roweis (Eds.), Advances in Neural Information Processing Systems (Vol. 20). Retrieved from https://proceedings.neurips.cc/paper_files/paper/2007/file/a9a1d5317a33ae8cef33961c34144f84-Paper.pdf\n\n\n\nAlgorithms\n\nYe, H., Deyle, E. R., Gilarranz, L. J., & Sugihara, G. (2015). Distinguishing time-delayed causal interactions using convergent cross mapping. Scientific Reports, 5, 14750. https://doi.org/10.1038/srep14750\nLe, T. D., Hoang, T., Li, J., Liu, L., Liu, H., & Hu, S. (2019). A Fast PC Algorithm for High Dimensional Causal Discovery with Multi-Core PCs. IEEE/ACM Transactions on Computational Biology and Bioinformatics / IEEE, ACM, 16(5), 1483–1495. &lt;https://doi.org/10.1109/TCBB.2016.2591526\nLangford, J., Salakhutdinov, R., & Zhang, T. (2009, May 20). Learning Nonlinear Dynamic Models. arXiv [cs.AI]. Retrieved from http://arxiv.org/abs/0905.3369\nLittman, M. L., Sutton, R. S., & Singh, S. (n.d.). Predictive Representations of State. In NIPS 2001. Retrieved from https://web.eecs.umich.edu/~baveja/Papers/psr.pdf\nChalupka, K., Perona, P., & Eberhardt, F. (2014, December 7). Visual Causal Feature Learning. arXiv [stat.ML]. Retrieved from http://arxiv.org/abs/1412.2309\nHefny, A., Downey, C., & Gordon, G. (2015, May 20). Supervised Learning for Dynamical System Learning. arXiv [stat.ML]. Retrieved from ,http://arxiv.org/abs/1505.05310&gt;\nSubramanian, J., Sinha, A., Seraj, R., & Mahajan, A. (2022). Approximate Information State for Approximate Planning and Reinforcement Learning in Partially Observed Systems. Journal of Machine Learning Research: JMLR, 23(12), 1–83. Retrieved from https://jmlr.org/papers/v23/20-1165.html"
  },
  {
    "objectID": "posts/deep-uncertainty-subjective-probability/index.html",
    "href": "posts/deep-uncertainty-subjective-probability/index.html",
    "title": "Deep Uncertainty and Subjective Probabilities",
    "section": "",
    "text": "Deep uncertainty is an extremely useful concept — it’s good to explicitly recognize that there is no consensus probability distribution as a red flag for the use of typical decision-making under uncertainty approaches. However, this can be taken to an extreme level: because there is no consensus distribution, one should avoid the use of probabilities altogether.\n\n\nAs Morgan & Keith (2008) discuss, people impose probabilities when they’re absent. The Representative Concentration Pathways (RCPs) are a good example: in the absence of guidance about probabilities, various papers have treated all of the RCPs as equally likely (equivalent to a uniform distribution), or focused on specific RCPs at the expense of others (implicitly assigning uneven probabilities). For example, many papers focus on RCP 8.5, the most extreme scenario: in some cases, this gives the highest climate-change-signal-to-noise ratio, but this actually appears to be a highly unlikely scenario, and without that contextualization, this can create biases in decision-making.\nThis results in an epistemic hand-off from analyst to stakeholders, as stakeholders then have to impose their beliefs without guidance. It’s also unlikely1 that the analyst shows how different beliefs This may be appropriate in some cases, when the local domain knowledge is stronger than the analyst’s knowledge, but may also result in political differences emerging by working backwards from desired outcomes2. This may be worsened by the Ellsberg Paradox when stakeholders are faced with deep uncertainty.1 But not impossible; a lot of the advanced analytics that accompany frameworks like Multi-Objective Robust Decision Making get at this2 This can happen anyway, but we can make it more transparent\n\n\n\nApproaches like robustness and satisfycing are mostly fine: pick a solution that seems acceptable, and then stress-test it to make sure it performs adequately across scenarios3. Of course, this begs the question somewhat, as the robustness and satisfying scores will depend on how frequently poor-performing scenarios are sampled: is this an artifact of the implicit uniform distribution?4 A good sensitivity analysis can diagnose this type of issue, but may not be refelcted in a robustness-maximizing approach.3 Picking the threshold is another issue…4 The RCP example is instructive here: is RCP 8.5 20% of your samples?\nIn other words, should robustness be a tool only for post-facto analysis? It may be inappropriate to use it as an exploratory decision criteria. This case probably reduces to a Bayes estimator with some loss function under the uniform assumption. It would be useful to know what that loss function looks like."
  },
  {
    "objectID": "posts/deep-uncertainty-subjective-probability/index.html#the-problems-with-deep-uncertainty",
    "href": "posts/deep-uncertainty-subjective-probability/index.html#the-problems-with-deep-uncertainty",
    "title": "Deep Uncertainty and Subjective Probabilities",
    "section": "",
    "text": "Deep uncertainty is an extremely useful concept — it’s good to explicitly recognize that there is no consensus probability distribution as a red flag for the use of typical decision-making under uncertainty approaches. However, this can be taken to an extreme level: because there is no consensus distribution, one should avoid the use of probabilities altogether.\n\n\nAs Morgan & Keith (2008) discuss, people impose probabilities when they’re absent. The Representative Concentration Pathways (RCPs) are a good example: in the absence of guidance about probabilities, various papers have treated all of the RCPs as equally likely (equivalent to a uniform distribution), or focused on specific RCPs at the expense of others (implicitly assigning uneven probabilities). For example, many papers focus on RCP 8.5, the most extreme scenario: in some cases, this gives the highest climate-change-signal-to-noise ratio, but this actually appears to be a highly unlikely scenario, and without that contextualization, this can create biases in decision-making.\nThis results in an epistemic hand-off from analyst to stakeholders, as stakeholders then have to impose their beliefs without guidance. It’s also unlikely1 that the analyst shows how different beliefs This may be appropriate in some cases, when the local domain knowledge is stronger than the analyst’s knowledge, but may also result in political differences emerging by working backwards from desired outcomes2. This may be worsened by the Ellsberg Paradox when stakeholders are faced with deep uncertainty.1 But not impossible; a lot of the advanced analytics that accompany frameworks like Multi-Objective Robust Decision Making get at this2 This can happen anyway, but we can make it more transparent\n\n\n\nApproaches like robustness and satisfycing are mostly fine: pick a solution that seems acceptable, and then stress-test it to make sure it performs adequately across scenarios3. Of course, this begs the question somewhat, as the robustness and satisfying scores will depend on how frequently poor-performing scenarios are sampled: is this an artifact of the implicit uniform distribution?4 A good sensitivity analysis can diagnose this type of issue, but may not be refelcted in a robustness-maximizing approach.3 Picking the threshold is another issue…4 The RCP example is instructive here: is RCP 8.5 20% of your samples?\nIn other words, should robustness be a tool only for post-facto analysis? It may be inappropriate to use it as an exploratory decision criteria. This case probably reduces to a Bayes estimator with some loss function under the uniform assumption. It would be useful to know what that loss function looks like."
  },
  {
    "objectID": "posts/deep-uncertainty-subjective-probability/index.html#embracing-subjective-probabilities",
    "href": "posts/deep-uncertainty-subjective-probability/index.html#embracing-subjective-probabilities",
    "title": "Deep Uncertainty and Subjective Probabilities",
    "section": "Embracing Subjective Probabilities",
    "text": "Embracing Subjective Probabilities\nThe alternative is to lean into subjectivity: based on the domain knowledge the expert has or has elicited, what probabilities would they assign and what does that mean about the decision space? Ideally, the analyst doesn’t stop there and looks at how different assignments of probability influence the decision analysis. This would make both a forwards (probability -&gt; outcome) and backwards (outcomes -&gt; probability) process more transparent."
  },
  {
    "objectID": "posts/deep-uncertainty-subjective-probability/index.html#things-i-need-to-think-about-more",
    "href": "posts/deep-uncertainty-subjective-probability/index.html#things-i-need-to-think-about-more",
    "title": "Deep Uncertainty and Subjective Probabilities",
    "section": "Things I Need To Think About More",
    "text": "Things I Need To Think About More\n\nWhat is the loss equivalent of robustness?\nHow seriously should we take the epistemic-ethical implications of an analyst refusing to look at probabilities? When is it appropriate?\nCommunicating uncertainties is hard. Is it worse when we’re up front about these being subjective?"
  },
  {
    "objectID": "posts/deep-uncertainty-subjective-probability/index.html#relevant-reading",
    "href": "posts/deep-uncertainty-subjective-probability/index.html#relevant-reading",
    "title": "Deep Uncertainty and Subjective Probabilities",
    "section": "Relevant Reading",
    "text": "Relevant Reading\n\nMorgan, M. G., & Keith, D. W. (2008). Improving the way we think about projecting future energy use and emissions of carbon dioxide. Climatic Change, 90(3), 189–215. https://doi.org/10.1007/s10584-008-9458-1\nDoss-Gollin, J., & Keller, K. (2023). A subjective Bayesian framework for synthesizing deep uncertainties in climate risk management. Earth’s Future, 11(1), e2022EF003044. https://doi.org/10.1029/2022ef003044\nKatzav, J., Thompson, E. L., Risbey, J., Stainforth, D. A., Bradley, S., & Frisch, M. (2021). On the appropriate and inappropriate uses of probability distributions in climate projections and some alternatives. Climatic Change, 169(1), 15. https://doi.org/10.1007/s10584-021-03267-x"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Notebooks",
    "section": "",
    "text": "Title\n\n\nDate\n\n\nModified\n\n\n\n\n\n\nDeep Uncertainty and Subjective Probabilities\n\n\n6/9/23\n\n\n6/10/23\n\n\n\n\nState-Space Reconstruction\n\n\n6/10/23\n\n\n6/10/23\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About These Notes",
    "section": "",
    "text": "These are my notebooks, which serve mostly to organize my thoughts on topics I find interesting. If they’re useful to you, great! If not, oh well. And if they’re mostly incoherent, I guess that’s to be expected. Nothing is finalized, everything is a work in progress.\nIf you’re also interested in any of these topics and have thoughts, please feel free to let me know."
  }
]